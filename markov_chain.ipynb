{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b261bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e51d8",
   "metadata": {},
   "source": [
    "# Markov Chain with Extended State Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a980096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 sale episodes\n",
      "Found 22 no-sale episodes\n",
      "Sale duration: min=3, median=7.0, max=8\n",
      "No-sale duration: min=1, median=28.0, max=70\n",
      "Sale median: 7.0 days\n",
      "Sale boundaries: 33% = 2.3 → 2, 66% = 4.6 → 5\n",
      "No-sale median: 28.0 days\n",
      "No-sale boundaries: 33% = 9.2 → 9, 66% = 18.5 → 18\n",
      "State boundaries: {'sale_early_max': 2, 'sale_mid_max': 5, 'no_sale_recent_max': 9, 'no_sale_medium_max': 18}\n",
      "\n",
      "First 20 rows with extended states:\n",
      "         Date  Price simple_state extended_state\n",
      "0  2023-05-21   3.59            N       N_recent\n",
      "1  2023-05-22   3.59            N       N_recent\n",
      "2  2023-05-23   3.59            N       N_recent\n",
      "3  2023-05-24   3.59            N       N_recent\n",
      "4  2023-05-25   3.59            N       N_recent\n",
      "5  2023-05-26   3.59            N       N_recent\n",
      "6  2023-05-27   3.59            N       N_recent\n",
      "7  2023-05-28   3.59            N       N_recent\n",
      "8  2023-05-29   3.59            N       N_recent\n",
      "9  2023-05-30   3.59            N       N_medium\n",
      "10 2023-05-31   2.19            S        S_early\n",
      "11 2023-06-01   2.19            S        S_early\n",
      "12 2023-06-02   2.19            S          S_mid\n",
      "13 2023-06-03   2.19            S          S_mid\n",
      "14 2023-06-04   3.59            N       N_recent\n",
      "15 2023-06-05   3.59            N       N_recent\n",
      "16 2023-06-06   3.59            N       N_recent\n",
      "17 2023-06-07   3.59            N       N_recent\n",
      "18 2023-06-08   3.59            N       N_recent\n",
      "19 2023-06-09   3.59            N       N_recent\n",
      "\n",
      "Extended state distribution:\n",
      "extended_state\n",
      "N_old       253\n",
      "N_recent    186\n",
      "N_medium    151\n",
      "S_mid        60\n",
      "S_early      42\n",
      "S_late       38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 5 episodes:\n",
      "Episode 1: {'state': 'N', 'start_idx': 0, 'end_idx': 9, 'duration': 10}\n",
      "Episode 2: {'state': 'S', 'start_idx': 10, 'end_idx': 13, 'duration': 4}\n",
      "Episode 3: {'state': 'N', 'start_idx': 14, 'end_idx': 48, 'duration': 35}\n",
      "Episode 4: {'state': 'S', 'start_idx': 49, 'end_idx': 55, 'duration': 7}\n",
      "Episode 5: {'state': 'N', 'start_idx': 56, 'end_idx': 97, 'duration': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "def detect_sales_robust(df: pd.DataFrame, price_col: str = 'Price', \n",
    "                       method: str = 'rolling_quantile', **kwargs) -> pd.Series:\n",
    "\n",
    "    if method == 'simple_mode':\n",
    "        regular_price = df[price_col].mode().iloc[0]\n",
    "        sale_threshold = regular_price * kwargs.get('threshold', 0.8)\n",
    "        return np.where(df[price_col] < sale_threshold, 'S', 'N')\n",
    "    \n",
    "    elif method == 'rolling_quantile':\n",
    "        window = kwargs.get('window', 60)\n",
    "        quantile = kwargs.get('quantile', 0.8)\n",
    "        threshold = kwargs.get('threshold', 0.8)\n",
    "        \n",
    "        normal_price = df[price_col].rolling(window=window, min_periods=10).quantile(quantile)\n",
    "        normal_price = normal_price.fillna(method='bfill')\n",
    "        \n",
    "        sale_threshold = normal_price * threshold\n",
    "        return np.where(df[price_col] < sale_threshold, 'S', 'N')\n",
    "\n",
    "\n",
    "def identify_episodes(states: np.ndarray) -> List[Dict]:\n",
    "    episodes = []\n",
    "    \n",
    "    if len(states) == 0:\n",
    "        return episodes\n",
    "    \n",
    "    current_state = states[0]\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i in range(1, len(states)):\n",
    "        if states[i] != current_state:\n",
    "            episodes.append({\n",
    "                'state': current_state,\n",
    "                'start_idx': start_idx,\n",
    "                'end_idx': i - 1,\n",
    "                'duration': i - start_idx\n",
    "            })\n",
    "            \n",
    "            current_state = states[i]\n",
    "            start_idx = i\n",
    "    \n",
    "    episodes.append({\n",
    "        'state': current_state,\n",
    "        'start_idx': start_idx,\n",
    "        'end_idx': len(states) - 1,\n",
    "        'duration': len(states) - start_idx\n",
    "    })\n",
    "    \n",
    "    return episodes\n",
    "\n",
    "\n",
    "def calculate_state_boundaries(episodes: List[Dict], method: str = 'median_fraction') -> Dict:\n",
    "    sale_durations = [ep['duration'] for ep in episodes if ep['state'] == 'S']\n",
    "    no_sale_durations = [ep['duration'] for ep in episodes if ep['state'] == 'N']\n",
    "    \n",
    "    if method == 'median_fraction':\n",
    "        if sale_durations:\n",
    "            sale_median = np.median(sale_durations)\n",
    "            sale_early_max = max(1, round(0.33 * sale_median))\n",
    "            sale_mid_max = max(sale_early_max + 1, round(0.66 * sale_median))\n",
    "            \n",
    "            print(f\"Sale median: {sale_median} days\")\n",
    "            print(f\"Sale boundaries: 33% = {0.33 * sale_median:.1f} → {sale_early_max}, 66% = {0.66 * sale_median:.1f} → {sale_mid_max}\")\n",
    "        else:\n",
    "            sale_early_max = 3\n",
    "            sale_mid_max = 7\n",
    "        \n",
    "        if no_sale_durations:\n",
    "            no_sale_median = np.median(no_sale_durations)\n",
    "            no_sale_recent_max = max(1, round(0.33 * no_sale_median))\n",
    "            no_sale_medium_max = max(no_sale_recent_max + 1, round(0.66 * no_sale_median))\n",
    "            \n",
    "            print(f\"No-sale median: {no_sale_median} days\")\n",
    "            print(f\"No-sale boundaries: 33% = {0.33 * no_sale_median:.1f} → {no_sale_recent_max}, 66% = {0.66 * no_sale_median:.1f} → {no_sale_medium_max}\")\n",
    "        else:\n",
    "            no_sale_recent_max = 10\n",
    "            no_sale_medium_max = 25\n",
    "        \n",
    "        boundaries = {\n",
    "            'sale_early_max': sale_early_max,\n",
    "            'sale_mid_max': sale_mid_max,\n",
    "            'no_sale_recent_max': no_sale_recent_max,\n",
    "            'no_sale_medium_max': no_sale_medium_max\n",
    "        }\n",
    "        \n",
    "    elif method == 'manual':\n",
    "        # Manual boundaries (easily adjustable)\n",
    "        boundaries = {\n",
    "            'sale_early_max': 3,\n",
    "            'sale_mid_max': 7,\n",
    "            'no_sale_recent_max': 10,\n",
    "            'no_sale_medium_max': 25\n",
    "        }\n",
    "    \n",
    "    return boundaries\n",
    "\n",
    "\n",
    "def assign_extended_states(df: pd.DataFrame, episodes: List[Dict], \n",
    "                          boundaries: Dict) -> pd.Series:\n",
    "    extended_states = np.full(len(df), '', dtype=object)\n",
    "    \n",
    "    for episode in episodes:\n",
    "        start_idx = episode['start_idx']\n",
    "        end_idx = episode['end_idx']\n",
    "        state_type = episode['state']\n",
    "        \n",
    "        for day_idx in range(start_idx, end_idx + 1):\n",
    "            days_into_episode = day_idx - start_idx + 1\n",
    "            \n",
    "            if state_type == 'S':\n",
    "                if days_into_episode <= boundaries['sale_early_max']:\n",
    "                    extended_states[day_idx] = 'S_early'\n",
    "                elif days_into_episode <= boundaries['sale_mid_max']:\n",
    "                    extended_states[day_idx] = 'S_mid'\n",
    "                else:\n",
    "                    extended_states[day_idx] = 'S_late'\n",
    "            \n",
    "            else:\n",
    "                if days_into_episode <= boundaries['no_sale_recent_max']:\n",
    "                    extended_states[day_idx] = 'N_recent'\n",
    "                elif days_into_episode <= boundaries['no_sale_medium_max']:\n",
    "                    extended_states[day_idx] = 'N_medium'\n",
    "                else:\n",
    "                    extended_states[day_idx] = 'N_old'\n",
    "    \n",
    "    return pd.Series(extended_states, index=df.index)\n",
    "\n",
    "\n",
    "def process_product_data(filename: str, sale_detection_method: str = 'rolling_quantile',\n",
    "                        boundary_method: str = 'percentile') -> Tuple[pd.DataFrame, Dict]:\n",
    "    df = pd.read_csv(filename)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    df['simple_state'] = detect_sales_robust(df, method=sale_detection_method)\n",
    "    \n",
    "    episodes = identify_episodes(df['simple_state'].values)\n",
    "    \n",
    "    sale_episodes = [ep for ep in episodes if ep['state'] == 'S']\n",
    "    no_sale_episodes = [ep for ep in episodes if ep['state'] == 'N']\n",
    "    \n",
    "    print(f\"Found {len(sale_episodes)} sale episodes\")\n",
    "    print(f\"Found {len(no_sale_episodes)} no-sale episodes\")\n",
    "    \n",
    "    if sale_episodes:\n",
    "        sale_durations = [ep['duration'] for ep in sale_episodes]\n",
    "        print(f\"Sale duration: min={min(sale_durations)}, median={np.median(sale_durations):.1f}, max={max(sale_durations)}\")\n",
    "    \n",
    "    if no_sale_episodes:\n",
    "        no_sale_durations = [ep['duration'] for ep in no_sale_episodes]\n",
    "        print(f\"No-sale duration: min={min(no_sale_durations)}, median={np.median(no_sale_durations):.1f}, max={max(no_sale_durations)}\")\n",
    "    \n",
    "    boundaries = calculate_state_boundaries(episodes, method=boundary_method)\n",
    "    print(f\"State boundaries: {boundaries}\")\n",
    "    \n",
    "    df['extended_state'] = assign_extended_states(df, episodes, boundaries)\n",
    "    \n",
    "    analysis_results = {\n",
    "        'episodes': episodes,\n",
    "        'boundaries': boundaries,\n",
    "        'sale_episodes': len(sale_episodes),\n",
    "        'no_sale_episodes': len(no_sale_episodes),\n",
    "        'sale_durations': [ep['duration'] for ep in sale_episodes],\n",
    "        'no_sale_durations': [ep['duration'] for ep in no_sale_episodes]\n",
    "    }\n",
    "    \n",
    "    return df, analysis_results\n",
    "\n",
    "\n",
    "filename = 'datasets/price_data_pesto.csv'\n",
    "\n",
    "df_processed, results = process_product_data(\n",
    "    filename, \n",
    "    sale_detection_method='rolling_quantile',\n",
    "    boundary_method='median_fraction'\n",
    ")\n",
    "\n",
    "print(\"\\nFirst 20 rows with extended states:\")\n",
    "print(df_processed[['Date', 'Price', 'simple_state', 'extended_state']].head(20))\n",
    "\n",
    "print(\"\\nExtended state distribution:\")\n",
    "print(df_processed['extended_state'].value_counts())\n",
    "\n",
    "print(\"\\nFirst 5 episodes:\")\n",
    "for i, episode in enumerate(results['episodes'][:5]):\n",
    "    print(f\"Episode {i+1}: {episode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85cc951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended Transition Matrix for product datasets/price_data_pesto.csv\n",
      "               To S_early  To S_mid  To S_late  To N_recent  To N_medium  \\\n",
      "From S_early        0.500      0.50      0.000        0.000        0.000   \n",
      "From S_mid          0.000      0.65      0.317        0.033        0.000   \n",
      "From S_late         0.000      0.00      0.500        0.500        0.000   \n",
      "From N_recent       0.011      0.00      0.000        0.886        0.103   \n",
      "From N_medium       0.026      0.00      0.000        0.000        0.874   \n",
      "From N_old          0.059      0.00      0.000        0.000        0.000   \n",
      "\n",
      "               To N_old  \n",
      "From S_early      0.000  \n",
      "From S_mid        0.000  \n",
      "From S_late       0.000  \n",
      "From N_recent     0.000  \n",
      "From N_medium     0.099  \n",
      "From N_old        0.941  \n",
      "\n",
      "Row sums (should be 1.0): [1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Transition counts:\n",
      "N_medium -> N_medium: 132\n",
      "N_medium -> N_old: 15\n",
      "N_medium -> S_early: 4\n",
      "N_old -> N_old: 238\n",
      "N_old -> S_early: 15\n",
      "N_recent -> N_medium: 19\n",
      "N_recent -> N_recent: 164\n",
      "N_recent -> S_early: 2\n",
      "S_early -> S_early: 21\n",
      "S_early -> S_mid: 21\n",
      "S_late -> N_recent: 19\n",
      "S_late -> S_late: 19\n",
      "S_mid -> N_recent: 2\n",
      "S_mid -> S_late: 19\n",
      "S_mid -> S_mid: 39\n",
      "\n",
      "=== MANUAL STATE PREDICTIONS ===\n",
      "Day 1: 100.00% chance of sale\n",
      "Day 2: 98.33% chance of sale\n",
      "Day 3: 88.52% chance of sale\n",
      "Day 4: 73.92% chance of sale\n",
      "Day 5: 58.51% chance of sale\n",
      "Day 6: 44.74% chance of sale\n",
      "Day 7: 33.64% chance of sale\n",
      "Day 8: 25.35% chance of sale\n",
      "Day 9: 19.52% chance of sale\n",
      "Day 10: 15.68% chance of sale\n",
      "State distribution:\n",
      "extended_state\n",
      "N_old       253\n",
      "N_recent    186\n",
      "N_medium    151\n",
      "S_mid        60\n",
      "S_early      42\n",
      "S_late       38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "extended_states = df_processed['extended_state'].values\n",
    "extended_transitions = [(extended_states[i], extended_states[i+1]) for i in range(len(extended_states)-1)]\n",
    "\n",
    "all_states = ['S_early', 'S_mid', 'S_late', 'N_recent', 'N_medium', 'N_old']\n",
    "state_to_idx = {state: i for i, state in enumerate(all_states)}\n",
    "\n",
    "transition_counts = Counter(extended_transitions)\n",
    "\n",
    "n_states = len(all_states)\n",
    "transition_matrix = np.zeros((n_states, n_states))\n",
    "\n",
    "for (from_state, to_state), count in transition_counts.items():\n",
    "    from_idx = state_to_idx[from_state]\n",
    "    to_idx = state_to_idx[to_state]\n",
    "    transition_matrix[from_idx][to_idx] = count\n",
    "\n",
    "for i in range(n_states):\n",
    "    row_sum = transition_matrix[i].sum()\n",
    "    if row_sum > 0:\n",
    "        transition_matrix[i] = transition_matrix[i] / row_sum\n",
    "\n",
    "transition_df = pd.DataFrame(\n",
    "    transition_matrix,\n",
    "    index=[f'From {state}' for state in all_states],\n",
    "    columns=[f'To {state}' for state in all_states]\n",
    ")\n",
    "\n",
    "print(f'Extended Transition Matrix for product {filename}')\n",
    "print(transition_df.round(3))\n",
    "\n",
    "row_sums = transition_matrix.sum(axis=1)\n",
    "print(f'\\nRow sums (should be 1.0): {row_sums.round(3)}')\n",
    "\n",
    "print(f'\\nTransition counts:')\n",
    "for (from_state, to_state), count in sorted(transition_counts.items()):\n",
    "    print(f'{from_state} -> {to_state}: {count}')\n",
    "\n",
    "def predict_sale_probability(transition_matrix, initial_state, days_ahead=10):\n",
    "    if initial_state not in state_to_idx:\n",
    "        raise ValueError(f\"Invalid initial state: {initial_state}. Must be one of {all_states}\")\n",
    "    \n",
    "    state_vector = np.zeros(len(all_states))\n",
    "    initial_idx = state_to_idx[initial_state]\n",
    "    state_vector[initial_idx] = 1.0\n",
    "    \n",
    "    forecast = []\n",
    "    \n",
    "    for day in range(1, days_ahead + 1):\n",
    "        state_vector = state_vector @ transition_matrix\n",
    "        \n",
    "        sale_probability = state_vector[0] + state_vector[1] + state_vector[2]\n",
    "        forecast.append(sale_probability)\n",
    "    \n",
    "    return forecast\n",
    "\n",
    "print(f'\\n=== MANUAL STATE PREDICTIONS ===')\n",
    "\n",
    "initial_state = 'S_early'\n",
    "days_ahead = 10\n",
    "forecast = predict_sale_probability(transition_matrix, initial_state, days_ahead)\n",
    "\n",
    "for day, day_forecast in enumerate(forecast, start=1):\n",
    "    print(f\"Day {day}: {day_forecast:.2%} chance of sale\")\n",
    "\n",
    "print(f'State distribution:')\n",
    "print(df_processed['extended_state'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de34a652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Product 1: datasets/price_data_pesto.csv\n",
      "Initial state: S_early\n",
      "--------------------------------------------------\n",
      "Found 21 sale episodes\n",
      "Found 22 no-sale episodes\n",
      "Sale duration: min=3, median=7.0, max=8\n",
      "No-sale duration: min=1, median=28.0, max=70\n",
      "Sale median: 7.0 days\n",
      "Sale boundaries: 33% = 2.3 → 2, 66% = 4.6 → 5\n",
      "No-sale median: 28.0 days\n",
      "No-sale boundaries: 33% = 9.2 → 9, 66% = 18.5 → 18\n",
      "State boundaries: {'sale_early_max': 2, 'sale_mid_max': 5, 'no_sale_recent_max': 9, 'no_sale_medium_max': 18}\n",
      "Forecast for Product 1:\n",
      "  Day 1: 100.00%\n",
      "  Day 2: 98.33%\n",
      "  Day 3: 88.52%\n",
      "  Day 4: 73.92%\n",
      "  Day 5: 58.51%\n",
      "  Day 6: 44.74%\n",
      "  Day 7: 33.64%\n",
      "  Day 8: 25.35%\n",
      "  Day 9: 19.52%\n",
      "  Day 10: 15.68%\n",
      "\n",
      "Processing Product 2: datasets/price_data_chicken.csv\n",
      "Initial state: S_early\n",
      "--------------------------------------------------\n",
      "Found 23 sale episodes\n",
      "Found 24 no-sale episodes\n",
      "Sale duration: min=5, median=7.0, max=21\n",
      "No-sale duration: min=7, median=14.0, max=70\n",
      "Sale median: 7.0 days\n",
      "Sale boundaries: 33% = 2.3 → 2, 66% = 4.6 → 5\n",
      "No-sale median: 14.0 days\n",
      "No-sale boundaries: 33% = 4.6 → 5, 66% = 9.2 → 9\n",
      "State boundaries: {'sale_early_max': 2, 'sale_mid_max': 5, 'no_sale_recent_max': 5, 'no_sale_medium_max': 9}\n",
      "Forecast for Product 2:\n",
      "  Day 1: 100.00%\n",
      "  Day 2: 99.28%\n",
      "  Day 3: 93.75%\n",
      "  Day 4: 84.27%\n",
      "  Day 5: 72.85%\n",
      "  Day 6: 61.36%\n",
      "  Day 7: 51.04%\n",
      "  Day 8: 42.57%\n",
      "  Day 9: 36.16%\n",
      "  Day 10: 31.73%\n",
      "\n",
      "Processing Product 3: datasets/price_data_coffee.csv\n",
      "Initial state: S_early\n",
      "--------------------------------------------------\n",
      "Found 21 sale episodes\n",
      "Found 21 no-sale episodes\n",
      "Sale duration: min=3, median=7.0, max=12\n",
      "No-sale duration: min=9, median=21.0, max=91\n",
      "Sale median: 7.0 days\n",
      "Sale boundaries: 33% = 2.3 → 2, 66% = 4.6 → 5\n",
      "No-sale median: 21.0 days\n",
      "No-sale boundaries: 33% = 6.9 → 7, 66% = 13.9 → 14\n",
      "State boundaries: {'sale_early_max': 2, 'sale_mid_max': 5, 'no_sale_recent_max': 7, 'no_sale_medium_max': 14}\n",
      "Forecast for Product 3:\n",
      "  Day 1: 100.00%\n",
      "  Day 2: 98.36%\n",
      "  Day 3: 90.86%\n",
      "  Day 4: 79.15%\n",
      "  Day 5: 65.82%\n",
      "  Day 6: 52.88%\n",
      "  Day 7: 41.50%\n",
      "  Day 8: 32.18%\n",
      "  Day 9: 25.00%\n",
      "  Day 10: 19.78%\n",
      "\n",
      "Processing Product 4: datasets/price_data_butter.csv\n",
      "Initial state: S_early\n",
      "--------------------------------------------------\n",
      "Found 16 sale episodes\n",
      "Found 16 no-sale episodes\n",
      "Sale duration: min=4, median=8.0, max=11\n",
      "No-sale duration: min=3, median=35.0, max=88\n",
      "Sale median: 8.0 days\n",
      "Sale boundaries: 33% = 2.6 → 3, 66% = 5.3 → 5\n",
      "No-sale median: 35.0 days\n",
      "No-sale boundaries: 33% = 11.6 → 12, 66% = 23.1 → 23\n",
      "State boundaries: {'sale_early_max': 3, 'sale_mid_max': 5, 'no_sale_recent_max': 12, 'no_sale_medium_max': 23}\n",
      "Forecast for Product 4:\n",
      "  Day 1: 100.00%\n",
      "  Day 2: 98.92%\n",
      "  Day 3: 93.45%\n",
      "  Day 4: 84.49%\n",
      "  Day 5: 73.83%\n",
      "  Day 6: 63.00%\n",
      "  Day 7: 52.98%\n",
      "  Day 8: 44.30%\n",
      "  Day 9: 37.11%\n",
      "  Day 10: 31.38%\n",
      "\n",
      "Processing Product 5: datasets/price_data_noodles.csv\n",
      "Initial state: S_early\n",
      "--------------------------------------------------\n",
      "Found 14 sale episodes\n",
      "Found 15 no-sale episodes\n",
      "Sale duration: min=7, median=7.0, max=7\n",
      "No-sale duration: min=3, median=46.0, max=120\n",
      "Sale median: 7.0 days\n",
      "Sale boundaries: 33% = 2.3 → 2, 66% = 4.6 → 5\n",
      "No-sale median: 46.0 days\n",
      "No-sale boundaries: 33% = 15.2 → 15, 66% = 30.4 → 30\n",
      "State boundaries: {'sale_early_max': 2, 'sale_mid_max': 5, 'no_sale_recent_max': 15, 'no_sale_medium_max': 30}\n",
      "Forecast for Product 5:\n",
      "  Day 1: 100.00%\n",
      "  Day 2: 100.00%\n",
      "  Day 3: 91.67%\n",
      "  Day 4: 77.90%\n",
      "  Day 5: 62.72%\n",
      "  Day 6: 48.77%\n",
      "  Day 7: 37.22%\n",
      "  Day 8: 28.33%\n",
      "  Day 9: 21.83%\n",
      "  Day 10: 17.27%\n",
      "\n",
      "=== AVERAGE PROBABILITIES ===\n",
      "Average probabilities for next 10 days:\n",
      "  Day 1: 100.00%\n",
      "  Day 2: 98.98%\n",
      "  Day 3: 91.65%\n",
      "  Day 4: 79.95%\n",
      "  Day 5: 66.75%\n",
      "  Day 6: 54.15%\n",
      "  Day 7: 43.28%\n",
      "  Day 8: 34.54%\n",
      "  Day 9: 27.92%\n",
      "  Day 10: 23.17%\n",
      "\n",
      "=== DETAILED PRODUCT COMPARISON ===\n",
      "Day  Product_1   Product_2   Product_3   Product_4   Product_5   Average   \n",
      "---------------------------------------------------------------------------\n",
      "1    100.0%       100.0%       100.0%       100.0%       100.0%       100.0%\n",
      "2    98.3%       99.3%       98.4%       98.9%       100.0%       99.0%\n",
      "3    88.5%       93.8%       90.9%       93.5%       91.7%       91.7%\n",
      "4    73.9%       84.3%       79.1%       84.5%       77.9%       79.9%\n",
      "5    58.5%       72.9%       65.8%       73.8%       62.7%       66.7%\n",
      "6    44.7%       61.4%       52.9%       63.0%       48.8%       54.1%\n",
      "7    33.6%       51.0%       41.5%       53.0%       37.2%       43.3%\n",
      "8    25.3%       42.6%       32.2%       44.3%       28.3%       34.5%\n",
      "9    19.5%       36.2%       25.0%       37.1%       21.8%       27.9%\n",
      "10   15.7%       31.7%       19.8%       31.4%       17.3%       23.2%\n",
      "\n",
      "Initial states:\n",
      "  Product_1: S_early\n",
      "  Product_2: S_early\n",
      "  Product_3: S_early\n",
      "  Product_4: S_early\n",
      "  Product_5: S_early\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n",
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n",
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n",
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n",
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "def multi_product_prediction(file_paths, initial_states, days_ahead=10):\n",
    "    if len(file_paths) != len(initial_states):\n",
    "        raise ValueError(\"Number of file paths must match number of initial states\")\n",
    "    \n",
    "    product_results = {}\n",
    "    all_forecasts = []\n",
    "    \n",
    "    for i, (file_path, initial_state) in enumerate(zip(file_paths, initial_states)):\n",
    "        print(f\"Processing Product {i+1}: {file_path}\")\n",
    "        print(f\"Initial state: {initial_state}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            df_processed, results = process_product_data(\n",
    "                file_path, \n",
    "                sale_detection_method='rolling_quantile',\n",
    "                boundary_method='median_fraction'\n",
    "            )\n",
    "            \n",
    "            extended_states = df_processed['extended_state'].values\n",
    "            extended_transitions = [(extended_states[j], extended_states[j+1]) \n",
    "                                  for j in range(len(extended_states)-1)]\n",
    "            \n",
    "            transition_counts = Counter(extended_transitions)\n",
    "            \n",
    "            transition_matrix = np.zeros((6, 6))\n",
    "            \n",
    "            for (from_state, to_state), count in transition_counts.items():\n",
    "                from_idx = state_to_idx[from_state]\n",
    "                to_idx = state_to_idx[to_state]\n",
    "                transition_matrix[from_idx][to_idx] = count\n",
    "            \n",
    "            for row in range(6):\n",
    "                row_sum = transition_matrix[row].sum()\n",
    "                if row_sum > 0:\n",
    "                    transition_matrix[row] = transition_matrix[row] / row_sum\n",
    "            \n",
    "            forecast = predict_sale_probability(transition_matrix, initial_state, days_ahead)\n",
    "            \n",
    "            product_results[f'Product_{i+1}'] = {\n",
    "                'file_path': file_path,\n",
    "                'initial_state': initial_state,\n",
    "                'forecast': forecast,\n",
    "                'transition_matrix': transition_matrix,\n",
    "                'df_processed': df_processed,\n",
    "                'results': results\n",
    "            }\n",
    "            \n",
    "            all_forecasts.append(forecast)\n",
    "            \n",
    "            print(f\"Forecast for Product {i+1}:\")\n",
    "            for day, prob in enumerate(forecast, start=1):\n",
    "                print(f\"  Day {day}: {prob:.2%}\")\n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing Product {i+1}: {e}\")\n",
    "            print()\n",
    "            continue\n",
    "    \n",
    "    if all_forecasts:\n",
    "        avg_forecast = []\n",
    "        for day in range(days_ahead):\n",
    "            day_probs = [forecast[day] for forecast in all_forecasts]\n",
    "            avg_prob = sum(day_probs) / len(day_probs)\n",
    "            avg_forecast.append(avg_prob)\n",
    "        \n",
    "        print(\"=== AVERAGE PROBABILITIES ===\")\n",
    "        print(f\"Average probabilities for next {days_ahead} days:\")\n",
    "        \n",
    "        for day, prob in enumerate(avg_forecast, start=1):\n",
    "            print(f\"  Day {day}: {prob:.2%}\")\n",
    "        \n",
    "        return {\n",
    "            'product_results': product_results,\n",
    "            'avg_forecast': avg_forecast,\n",
    "            'num_products': len(all_forecasts)\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        print(\"No products were successfully processed!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def display_detailed_comparison(results):\n",
    "    if not results:\n",
    "        print(\"No results to display\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n=== DETAILED PRODUCT COMPARISON ===\")\n",
    "    \n",
    "    days_to_show = 10\n",
    "    product_names = list(results['product_results'].keys())\n",
    "    \n",
    "    print(f\"{'Day':<5}\", end=\"\")\n",
    "    for product in product_names:\n",
    "        print(f\"{product:<12}\", end=\"\")\n",
    "    print(f\"{'Average':<10}\")\n",
    "    \n",
    "    print(\"-\" * (5 + 12 * len(product_names) + 10))\n",
    "    \n",
    "    for day in range(days_to_show):\n",
    "        print(f\"{day+1:<5}\", end=\"\")\n",
    "        \n",
    "        for product in product_names:\n",
    "            forecast = results['product_results'][product]['forecast']\n",
    "            prob = forecast[day] if day < len(forecast) else 0\n",
    "            print(f\"{prob:.1%}{'':>7}\", end=\"\")\n",
    "        \n",
    "        avg_prob = results['avg_forecast'][day] if day < len(results['avg_forecast']) else 0\n",
    "        print(f\"{avg_prob:.1%}\")\n",
    "    \n",
    "    print(f\"\\nInitial states:\")\n",
    "    for product in product_names:\n",
    "        initial_state = results['product_results'][product]['initial_state']\n",
    "        print(f\"  {product}: {initial_state}\")\n",
    "\n",
    "file_paths = [\n",
    "    'datasets/price_data_pesto.csv',\n",
    "    'datasets/price_data_chicken.csv',\n",
    "    'datasets/price_data_coffee.csv',\n",
    "    'datasets/price_data_butter.csv',\n",
    "    'datasets/price_data_noodles.csv'\n",
    "]\n",
    "\n",
    "initial_states = [\n",
    "    'S_early',\n",
    "    'S_early',\n",
    "    'S_early',\n",
    "    'S_early',\n",
    "    'S_early'\n",
    "]\n",
    "\n",
    "results = multi_product_prediction(file_paths, initial_states, days_ahead=10)\n",
    "\n",
    "if results:\n",
    "    display_detailed_comparison(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d9150a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRACTICAL SALE DURATION PREDICTION ===\n",
      "Threshold: 70.0%\n",
      "Evaluating Pesto.Csv:\n",
      "Found 21 sale episodes\n",
      "Found 22 no-sale episodes\n",
      "Sale duration: min=3, median=7.0, max=8\n",
      "No-sale duration: min=1, median=28.0, max=70\n",
      "Sale median: 7.0 days\n",
      "Sale boundaries: 33% = 2.3 → 2, 66% = 4.6 → 5\n",
      "No-sale median: 28.0 days\n",
      "No-sale boundaries: 33% = 9.2 → 9, 66% = 18.5 → 18\n",
      "State boundaries: {'sale_early_max': 2, 'sale_mid_max': 5, 'no_sale_recent_max': 9, 'no_sale_medium_max': 18}\n",
      "  Actual median total duration: 7 days\n",
      "  Expected remaining days after today: 6 days\n",
      "  Predicted remaining days: 4 days\n",
      "  Remaining days error: 2 days\n",
      "  Remaining days accuracy: 0.667\n",
      "  Day-by-day accuracy: 0.667\n",
      "  Daily probabilities: ['1.00', '0.98', '0.89', '0.74', '0.59', '0.45']\n",
      "  Prediction pattern: [1, 1, 1, 1, 0, 0]\n",
      "Evaluating Chicken.Csv:\n",
      "Found 23 sale episodes\n",
      "Found 24 no-sale episodes\n",
      "Sale duration: min=5, median=7.0, max=21\n",
      "No-sale duration: min=7, median=14.0, max=70\n",
      "Sale median: 7.0 days\n",
      "Sale boundaries: 33% = 2.3 → 2, 66% = 4.6 → 5\n",
      "No-sale median: 14.0 days\n",
      "No-sale boundaries: 33% = 4.6 → 5, 66% = 9.2 → 9\n",
      "State boundaries: {'sale_early_max': 2, 'sale_mid_max': 5, 'no_sale_recent_max': 5, 'no_sale_medium_max': 9}\n",
      "  Actual median total duration: 7 days\n",
      "  Expected remaining days after today: 6 days\n",
      "  Predicted remaining days: 5 days\n",
      "  Remaining days error: 1 days\n",
      "  Remaining days accuracy: 0.833\n",
      "  Day-by-day accuracy: 0.833\n",
      "  Daily probabilities: ['1.00', '0.99', '0.94', '0.84', '0.73', '0.61']\n",
      "  Prediction pattern: [1, 1, 1, 1, 1, 0]\n",
      "Evaluating Coffee.Csv:\n",
      "Found 21 sale episodes\n",
      "Found 21 no-sale episodes\n",
      "Sale duration: min=3, median=7.0, max=12\n",
      "No-sale duration: min=9, median=21.0, max=91\n",
      "Sale median: 7.0 days\n",
      "Sale boundaries: 33% = 2.3 → 2, 66% = 4.6 → 5\n",
      "No-sale median: 21.0 days\n",
      "No-sale boundaries: 33% = 6.9 → 7, 66% = 13.9 → 14\n",
      "State boundaries: {'sale_early_max': 2, 'sale_mid_max': 5, 'no_sale_recent_max': 7, 'no_sale_medium_max': 14}\n",
      "  Actual median total duration: 7 days\n",
      "  Expected remaining days after today: 6 days\n",
      "  Predicted remaining days: 4 days\n",
      "  Remaining days error: 2 days\n",
      "  Remaining days accuracy: 0.667\n",
      "  Day-by-day accuracy: 0.667\n",
      "  Daily probabilities: ['1.00', '0.98', '0.91', '0.79', '0.66', '0.53']\n",
      "  Prediction pattern: [1, 1, 1, 1, 0, 0]\n",
      "Evaluating Butter.Csv:\n",
      "Found 16 sale episodes\n",
      "Found 16 no-sale episodes\n",
      "Sale duration: min=4, median=8.0, max=11\n",
      "No-sale duration: min=3, median=35.0, max=88\n",
      "Sale median: 8.0 days\n",
      "Sale boundaries: 33% = 2.6 → 3, 66% = 5.3 → 5\n",
      "No-sale median: 35.0 days\n",
      "No-sale boundaries: 33% = 11.6 → 12, 66% = 23.1 → 23\n",
      "State boundaries: {'sale_early_max': 3, 'sale_mid_max': 5, 'no_sale_recent_max': 12, 'no_sale_medium_max': 23}\n",
      "  Actual median total duration: 8 days\n",
      "  Expected remaining days after today: 7 days\n",
      "  Predicted remaining days: 5 days\n",
      "  Remaining days error: 2 days\n",
      "  Remaining days accuracy: 0.714\n",
      "  Day-by-day accuracy: 0.714\n",
      "  Daily probabilities: ['1.00', '0.99', '0.93', '0.84', '0.74', '0.63', '0.53']\n",
      "  Prediction pattern: [1, 1, 1, 1, 1, 0, 0]\n",
      "Evaluating Noodles.Csv:\n",
      "Found 14 sale episodes\n",
      "Found 15 no-sale episodes\n",
      "Sale duration: min=7, median=7.0, max=7\n",
      "No-sale duration: min=3, median=46.0, max=120\n",
      "Sale median: 7.0 days\n",
      "Sale boundaries: 33% = 2.3 → 2, 66% = 4.6 → 5\n",
      "No-sale median: 46.0 days\n",
      "No-sale boundaries: 33% = 15.2 → 15, 66% = 30.4 → 30\n",
      "State boundaries: {'sale_early_max': 2, 'sale_mid_max': 5, 'no_sale_recent_max': 15, 'no_sale_medium_max': 30}\n",
      "  Actual median total duration: 7 days\n",
      "  Expected remaining days after today: 6 days\n",
      "  Predicted remaining days: 4 days\n",
      "  Remaining days error: 2 days\n",
      "  Remaining days accuracy: 0.667\n",
      "  Day-by-day accuracy: 0.667\n",
      "  Daily probabilities: ['1.00', '1.00', '0.92', '0.78', '0.63', '0.49']\n",
      "  Prediction pattern: [1, 1, 1, 1, 0, 0]\n",
      "=== OVERALL RESULTS ===\n",
      "Average remaining days error: 1.80 days\n",
      "Average remaining days accuracy: 0.710\n",
      "Average day-by-day accuracy: 0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n",
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n",
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n",
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n",
      "C:\\Users\\pgaug\\AppData\\Local\\Temp\\ipykernel_7356\\93707491.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  normal_price = normal_price.fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "def evaluate_practical_sale_prediction(file_paths, threshold=0.6):\n",
    "    print(\"=== PRACTICAL SALE DURATION PREDICTION ===\")\n",
    "    print(f\"Threshold: {threshold:.1%}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        product_name = file_path.split('/')[-1].replace('.txt', '').replace('price_data_', '').title()\n",
    "        print(f\"Evaluating {product_name}:\")\n",
    "        \n",
    "        df_processed, analysis_results = process_product_data(\n",
    "            file_path, \n",
    "            sale_detection_method='rolling_quantile',\n",
    "            boundary_method='median_fraction'\n",
    "        )\n",
    "        \n",
    "        actual_median_duration = int(np.median(analysis_results['sale_durations'])) if analysis_results['sale_durations'] else 7\n",
    "        expected_remaining_days = actual_median_duration - 1 \n",
    "        \n",
    "        print(f\"  Actual median total duration: {actual_median_duration} days\")\n",
    "        print(f\"  Expected remaining days after today: {expected_remaining_days} days\")\n",
    "        \n",
    "        extended_states = df_processed['extended_state'].values\n",
    "        extended_transitions = [(extended_states[j], extended_states[j+1]) \n",
    "                              for j in range(len(extended_states)-1)]\n",
    "        \n",
    "        transition_counts = Counter(extended_transitions)\n",
    "        transition_matrix = np.zeros((6, 6))\n",
    "        \n",
    "        for (from_state, to_state), count in transition_counts.items():\n",
    "            from_idx = state_to_idx[from_state]\n",
    "            to_idx = state_to_idx[to_state]\n",
    "            transition_matrix[from_idx][to_idx] = count\n",
    "        \n",
    "        for row in range(6):\n",
    "            row_sum = transition_matrix[row].sum()\n",
    "            if row_sum > 0:\n",
    "                transition_matrix[row] = transition_matrix[row] / row_sum\n",
    "        \n",
    "        if expected_remaining_days > 0:\n",
    "            forecast = predict_sale_probability(transition_matrix, 'S_early', expected_remaining_days)\n",
    "            \n",
    "            predicted_pattern = [1 if prob >= threshold else 0 for prob in forecast]\n",
    "            \n",
    "            predicted_remaining_days = 0\n",
    "            for day_prediction in predicted_pattern:\n",
    "                if day_prediction == 1:\n",
    "                    predicted_remaining_days += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "        else:\n",
    "            forecast = []\n",
    "            predicted_pattern = []\n",
    "            predicted_remaining_days = 0\n",
    "        \n",
    "        remaining_days_error = abs(predicted_remaining_days - expected_remaining_days)\n",
    "        remaining_days_accuracy = 1 - (remaining_days_error / expected_remaining_days) if expected_remaining_days > 0 else 1.0\n",
    "        \n",
    "        if expected_remaining_days > 0:\n",
    "            expected_pattern = [1] * expected_remaining_days\n",
    "            day_accuracy = sum(1 for i, pred in enumerate(predicted_pattern) if i < len(expected_pattern) and pred == expected_pattern[i]) / expected_remaining_days\n",
    "        else:\n",
    "            day_accuracy = 1.0\n",
    "        \n",
    "        total_predicted_duration = 1 + predicted_remaining_days\n",
    "        \n",
    "        results[product_name] = {\n",
    "            'actual_total_duration': actual_median_duration,\n",
    "            'expected_remaining_days': expected_remaining_days,\n",
    "            'predicted_remaining_days': predicted_remaining_days,\n",
    "            'total_predicted_duration': total_predicted_duration,\n",
    "            'remaining_days_error': remaining_days_error,\n",
    "            'remaining_days_accuracy': remaining_days_accuracy,\n",
    "            'day_accuracy': day_accuracy,\n",
    "            'probabilities': forecast,\n",
    "            'prediction_pattern': predicted_pattern,\n",
    "            'threshold': threshold\n",
    "        }\n",
    "        \n",
    "        print(f\"  Predicted remaining days: {predicted_remaining_days} days\")\n",
    "        print(f\"  Remaining days error: {remaining_days_error} days\")\n",
    "        print(f\"  Remaining days accuracy: {remaining_days_accuracy:.3f}\")\n",
    "        print(f\"  Day-by-day accuracy: {day_accuracy:.3f}\")\n",
    "        if forecast:\n",
    "            print(f\"  Daily probabilities: {[f'{p:.2f}' for p in forecast]}\")\n",
    "        print(f\"  Prediction pattern: {predicted_pattern}\")\n",
    "    \n",
    "    all_remaining_errors = [r['remaining_days_error'] for r in results.values()]\n",
    "    all_remaining_accuracies = [r['remaining_days_accuracy'] for r in results.values()]\n",
    "    all_day_accuracies = [r['day_accuracy'] for r in results.values()]\n",
    "    \n",
    "    print(\"=== OVERALL RESULTS ===\")\n",
    "    print(f\"Average remaining days error: {np.mean(all_remaining_errors):.2f} days\")\n",
    "    print(f\"Average remaining days accuracy: {np.mean(all_remaining_accuracies):.3f}\")\n",
    "    print(f\"Average day-by-day accuracy: {np.mean(all_day_accuracies):.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "practical_results = evaluate_practical_sale_prediction(file_paths, threshold=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
